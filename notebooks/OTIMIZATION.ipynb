{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc127188-0fbc-4e93-87cf-4e103e2410c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting optimization for: C:\\Users\\netos\\Downloads\\Berlin\\Dataset_Berlin_Marathon_1999-2025_original.csv ---\n",
      "Attempting to load CSV with auto-detection of separator...\n",
      "Critical Error loading CSV: The 'low_memory' option is not supported with the 'python' engine\n",
      "Retrying with explicit semicolon separator...\n",
      "Retry successful! Found 880779 rows.\n",
      "Initial memory usage: 107.52 MB\n",
      "Optimized memory usage: 40.31 MB\n",
      "Reduction: 62.5%\n",
      "Saving optimized data to: C:\\Users\\netos\\Downloads\\Berlin\\Dataset_Berlin_Marathon_1999-2025_original.parquet...\n",
      "Success! File saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "\n",
    "def optimize_and_convert_dataset(input_csv_path, output_path=None):\n",
    "    \"\"\"\n",
    "    Optimizes memory usage of a pandas DataFrame by downcasting numeric types\n",
    "    and converting low-cardinality string columns to categories.\n",
    "    Handles variable separators (;, \\t, ,) automatically.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"--- Starting optimization for: {input_csv_path} ---\")\n",
    "    \n",
    "    if not os.path.exists(input_csv_path):\n",
    "        print(f\"ERROR: File not found at {input_csv_path}\")\n",
    "        return\n",
    "\n",
    "    # 1. Load Data with Robust Settings\n",
    "    print(\"Attempting to load CSV with auto-detection of separator...\")\n",
    "    try:\n",
    "        # 'sep=None' forces python engine to sniff the delimiter\n",
    "        # 'on_bad_lines' skips lines that are truly broken (and warns us)\n",
    "        # 'encoding' handles special German characters (umlauts like ä, ö, ü)\n",
    "        df = pd.read_csv(\n",
    "            input_csv_path, \n",
    "            sep=None, \n",
    "            engine='python', \n",
    "            on_bad_lines='warn', \n",
    "            encoding='utf-8', # Try 'latin-1' if this fails\n",
    "            low_memory=False\n",
    "        )\n",
    "        print(f\"Load successful! Found {len(df)} rows and {len(df.columns)} columns.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Critical Error loading CSV: {e}\")\n",
    "        # Fallback: Try reading strictly with semicolon if auto-detect fails\n",
    "        print(\"Retrying with explicit semicolon separator...\")\n",
    "        try:\n",
    "            df = pd.read_csv(input_csv_path, sep=';', on_bad_lines='skip', encoding='latin-1', low_memory=False)\n",
    "            print(f\"Retry successful! Found {len(df)} rows.\")\n",
    "        except Exception as e2:\n",
    "             print(f\"Retry failed: {e2}\")\n",
    "             return\n",
    "\n",
    "    # Calculate initial memory usage\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(f'Initial memory usage: {start_mem:.2f} MB')\n",
    "\n",
    "    # 2. Iterate through columns to optimize types\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "\n",
    "        # A. Optimize Numeric Columns\n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            \n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float32) \n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "\n",
    "        # B. Optimize Object (String) Columns\n",
    "        else:\n",
    "            num_unique = len(df[col].unique())\n",
    "            num_total = len(df[col])\n",
    "            \n",
    "            # If unique values are less than 50% of total rows, convert to category\n",
    "            if num_unique / num_total < 0.5:\n",
    "                df[col] = df[col].astype('category')\n",
    "\n",
    "    # Calculate final memory usage\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(f'Optimized memory usage: {end_mem:.2f} MB')\n",
    "    print(f'Reduction: {100 * (start_mem - end_mem) / start_mem:.1f}%')\n",
    "\n",
    "    # 3. Save to Parquet\n",
    "    if output_path is None:\n",
    "        output_path = input_csv_path.replace('.csv', '.parquet')\n",
    "        \n",
    "    print(f\"Saving optimized data to: {output_path}...\")\n",
    "    try:\n",
    "        df.to_parquet(output_path, engine='pyarrow', compression='snappy')\n",
    "        print(\"Success! File saved.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving to Parquet: {e}\")\n",
    "\n",
    "# Get the current working directory of this notebook\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# REPLACE 'Dataset_Berlin_Marathon_1999-2025_original.csv' WITH YOUR ACTUAL FILENAME\n",
    "filename = 'Dataset_Berlin_Marathon_1999-2025_original.csv' \n",
    "\n",
    "# Create the full absolute path safely\n",
    "input_path = os.path.join(current_dir, filename)\n",
    "\n",
    "# Run the optimization\n",
    "optimize_and_convert_dataset(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fa390d-5cf4-4247-b6f7-a288b717812f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173b45bc-dcec-45ac-ba3d-d93686c0e2f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
