{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acb7be66-28e5-44da-bff8-52141bd8d6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Feature Engineering (v2) on Dataset_Berlin_Cleaned_Analysis_Ready.parquet ---\n",
      "Data Loaded successfully. Shape: (873334, 18)\n",
      "Diagnosing 'half' column...\n",
      "Original Dtype: category\n",
      "Sample values: ['01:03:54', '01:03:54', '01:03:54']\n",
      "Parsing 'half' split to seconds...\n",
      "Filtered 664 rows (0.08%) due to missing/invalid split data.\n",
      "Calculating Pacing Index and Slowdown metrics...\n",
      "Assigning Performance Categories...\n",
      "Removed 48 extreme pacing outliers.\n",
      "Saving engineered data to Dataset_Berlin_Features_Engineered.parquet...\n",
      "\n",
      "========================================\n",
      "FEATURE ENGINEERING REPORT (v2)\n",
      "========================================\n",
      "Total Runners Analyzed: 872622\n",
      "\n",
      "--- Sample Data (First 5 Rows) ---\n",
      "  gender      half  half_seconds     finish_time  pct_slowdown  hit_the_wall\n",
      "0      M  01:03:54        3834.0 0 days 02:06:44     -1.669275         False\n",
      "1      M  01:03:54        3834.0 0 days 02:06:57     -1.330203         False\n",
      "2      M  01:03:54        3834.0 0 days 02:08:31      1.121544         False\n",
      "3      M  01:03:55        3835.0 0 days 02:09:56      3.285528         False\n",
      "4      M  01:03:55        3835.0 0 days 02:10:37      4.354628         False\n",
      "\n",
      "--- The Wall Statistics ---\n",
      "Rate of runners hitting the wall (>20% slowdown): 15.68%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def perform_feature_engineering_v2(input_path, output_path):\n",
    "    \"\"\"\n",
    "    STEP 1 (CORRECTED): FEATURE ENGINEERING\n",
    "    \n",
    "    Fixes the issue where categorical columns were mistaken for numeric, causing 100% data loss.\n",
    "    \n",
    "    Goals:\n",
    "    1. Robustly parse 'half' split times to seconds.\n",
    "    2. Calculate Pacing Metrics (Pacing Index, % Slowdown).\n",
    "    3. Create Performance Categories.\n",
    "    4. Define 'The Wall'.\n",
    "    \n",
    "    Args:\n",
    "        input_path (str): Path to the cleaned parquet file.\n",
    "        output_path (str): Path to save the engineered dataset.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"--- Starting Feature Engineering (v2) on {input_path} ---\")\n",
    "    \n",
    "    # 1. LOAD DATA\n",
    "    # ---------------------------------------------------------\n",
    "    try:\n",
    "        df = pd.read_parquet(input_path)\n",
    "        print(f\"Data Loaded successfully. Shape: {df.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Critical Error loading file: {e}\")\n",
    "        return None\n",
    "\n",
    "    # 2. ROBUST TIME PARSING (THE FIX)\n",
    "    # ---------------------------------------------------------\n",
    "    \n",
    "    def safe_parse_time(time_val):\n",
    "        \"\"\"\n",
    "        Robustly converts various time formats to total seconds.\n",
    "        Handles: Strings ('01:30:00'), Categories, Floats, and NaNs.\n",
    "        \"\"\"\n",
    "        # Force conversion to string to handle 'category' dtype safely\n",
    "        s = str(time_val).strip()\n",
    "        \n",
    "        # Check for empty/missing values common in CSVs\n",
    "        if s.lower() in ['nan', 'none', '', '-', 'nat']:\n",
    "            return np.nan\n",
    "            \n",
    "        try:\n",
    "            parts = s.split(':')\n",
    "            if len(parts) == 3: # Format H:M:S (e.g., 01:30:45)\n",
    "                return int(parts[0])*3600 + int(parts[1])*60 + float(parts[2])\n",
    "            elif len(parts) == 2: # Format M:S (e.g., 59:30)\n",
    "                return int(parts[0])*60 + float(parts[1])\n",
    "            else:\n",
    "                # If it's just a number (e.g. '5400'), try returning it as float\n",
    "                try:\n",
    "                    return float(s)\n",
    "                except:\n",
    "                    return np.nan\n",
    "        except:\n",
    "            return np.nan\n",
    "\n",
    "    print(\"Diagnosing 'half' column...\")\n",
    "    print(f\"Original Dtype: {df['half'].dtype}\")\n",
    "    print(f\"Sample values: {df['half'].head(3).tolist()}\")\n",
    "\n",
    "    # Apply the parsing logic explicitly\n",
    "    print(\"Parsing 'half' split to seconds...\")\n",
    "    df['half_seconds'] = df['half'].apply(safe_parse_time)\n",
    "    \n",
    "    # Ensure 'time_seconds' (finish time) is also clean\n",
    "    # (It should be from the previous step, but we double-check)\n",
    "    df['time_seconds'] = pd.to_numeric(df['time_seconds'], errors='coerce')\n",
    "\n",
    "    # 3. FILTERING VALID DATA\n",
    "    # ---------------------------------------------------------\n",
    "    initial_count = len(df)\n",
    "    \n",
    "    # We need both valid total time AND valid half split to calculate pacing\n",
    "    df_engineered = df.dropna(subset=['time_seconds', 'half_seconds']).copy()\n",
    "    \n",
    "    # Sanity Check: Remove half marathons < 30 mins (1800s) -> Impossible/Error\n",
    "    df_engineered = df_engineered[df_engineered['half_seconds'] > 1800]\n",
    "    \n",
    "    dropped_count = initial_count - len(df_engineered)\n",
    "    print(f\"Filtered {dropped_count} rows ({dropped_count/initial_count:.2%}) due to missing/invalid split data.\")\n",
    "    \n",
    "    if len(df_engineered) == 0:\n",
    "        print(\"CRITICAL ERROR: All rows were dropped. Check the 'Sample values' printed above.\")\n",
    "        return None\n",
    "\n",
    "    # 4. CALCULATE PACING METRICS\n",
    "    # ---------------------------------------------------------\n",
    "    print(\"Calculating Pacing Index and Slowdown metrics...\")\n",
    "    \n",
    "    # Second Half = Total Time - First Half\n",
    "    df_engineered['second_half_seconds'] = df_engineered['time_seconds'] - df_engineered['half_seconds']\n",
    "    \n",
    "    # Pacing Index (PI)\n",
    "    # PI = 1.0 (Even Split), PI > 1.0 (Positive Split/Slowdown)\n",
    "    df_engineered['pacing_index'] = df_engineered['second_half_seconds'] / df_engineered['half_seconds']\n",
    "    \n",
    "    # % Slowdown \n",
    "    df_engineered['pct_slowdown'] = (df_engineered['pacing_index'] - 1) * 100\n",
    "\n",
    "    # Define \"Hitting The Wall\" (Categorical)\n",
    "    # Threshold: > 20% slowdown\n",
    "    df_engineered['hit_the_wall'] = df_engineered['pct_slowdown'] > 20.0\n",
    "\n",
    "    # 5. CREATE PERFORMANCE CATEGORIES\n",
    "    # ---------------------------------------------------------\n",
    "    print(\"Assigning Performance Categories...\")\n",
    "    \n",
    "    conditions = [\n",
    "        (df_engineered['time_seconds'] < 10800), # Sub 3h\n",
    "        (df_engineered['time_seconds'] >= 10800) & (df_engineered['time_seconds'] < 12600), # 3h-3h30\n",
    "        (df_engineered['time_seconds'] >= 12600) & (df_engineered['time_seconds'] < 14400), # 3h30-4h\n",
    "        (df_engineered['time_seconds'] >= 14400) & (df_engineered['time_seconds'] < 16200), # 4h-4h30\n",
    "        (df_engineered['time_seconds'] >= 16200) # > 4h30\n",
    "    ]\n",
    "    \n",
    "    category_labels = [\n",
    "        '1. Elite/Sub-3h (<3:00)',\n",
    "        '2. Advanced (3:00-3:30)',\n",
    "        '3. Intermediate (3:30-4:00)',\n",
    "        '4. Recreational (4:00-4:30)',\n",
    "        '5. Casual (>4:30)'\n",
    "    ]\n",
    "    \n",
    "    df_engineered['performance_level'] = np.select(conditions, category_labels, default='Unknown')\n",
    "\n",
    "    # 6. FINAL CLEANUP & SAVING\n",
    "    # ---------------------------------------------------------\n",
    "    # Remove extreme pacing outliers (PI < 0.5 or > 3.0)\n",
    "    clean_mask = (df_engineered['pacing_index'] > 0.5) & (df_engineered['pacing_index'] < 3.0)\n",
    "    df_final = df_engineered[clean_mask].copy()\n",
    "    \n",
    "    print(f\"Removed {len(df_engineered) - len(df_final)} extreme pacing outliers.\")\n",
    "    \n",
    "    print(f\"Saving engineered data to {output_path}...\")\n",
    "    df_final.to_parquet(output_path, engine='pyarrow')\n",
    "    \n",
    "    # 7. REPORTING\n",
    "    # ---------------------------------------------------------\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(\"FEATURE ENGINEERING REPORT (v2)\")\n",
    "    print(\"=\"*40)\n",
    "    print(f\"Total Runners Analyzed: {len(df_final)}\")\n",
    "    \n",
    "    print(\"\\n--- Sample Data (First 5 Rows) ---\")\n",
    "    print(df_final[['gender', 'half', 'half_seconds', 'finish_time', 'pct_slowdown', 'hit_the_wall']].head())\n",
    "    \n",
    "    print(\"\\n--- The Wall Statistics ---\")\n",
    "    wall_counts = df_final['hit_the_wall'].value_counts(normalize=True) * 100\n",
    "    print(f\"Rate of runners hitting the wall (>20% slowdown): {wall_counts.get(True, 0):.2f}%\")\n",
    "    \n",
    "    return df_final\n",
    "\n",
    "# --- EXECUTION BLOCK ---\n",
    "input_file = \"Dataset_Berlin_Cleaned_Analysis_Ready.parquet\"\n",
    "output_file = \"Dataset_Berlin_Features_Engineered.parquet\"\n",
    "\n",
    "df_features = perform_feature_engineering_v2(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ee0d1a8-faf3-45ec-8261-cf3325af5344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading Data from Dataset_Berlin_Features_Engineered.parquet ---\n",
      "\n",
      "============================================================\n",
      "MACRO VIEW: INTELLIGENCE REPORT (GENDER PACING DYNAMICS)\n",
      "============================================================\n",
      "\n",
      "[1] KEY METRICS TABLE:\n",
      "         Mean  Median  Std_Dev   Count  Skewness\n",
      "gender                                          \n",
      "F        8.34    6.71     8.85  213826      1.33\n",
      "M       10.71    8.09    11.24  658506      1.41\n",
      "\n",
      "[2] THE WALL ANALYSIS (>20% Slowdown):\n",
      "   - Men hitting the wall:   115,995 (17.61%)\n",
      "   - Women hitting the wall: 20,657 (9.66%)\n",
      "\n",
      "[3] EXECUTIVE INSIGHT:\n",
      "   Men are 8.0 percentage points more likely to hit the wall than women.\n",
      "   The higher skewness in men confirms a behavioral tendency towards extreme positive splits.\n",
      "============================================================\n",
      "\n",
      "Generating Figure 1 (Density Distribution - Publishable)...\n",
      "Saving Figure_1_Density.tiff...\n",
      "Generating Figure 2 (Boxplot with Stats - Publishable)...\n",
      "Calculating Statistical Significance...\n",
      "Saving Figure_2_Boxplot.tiff...\n",
      "\n",
      "[SUCCESS] Report printed and Images generated.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import skew, kurtosis\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings to keep the report clean\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def generate_comprehensive_analysis(input_path):\n",
    "    print(f\"--- Loading Data from {input_path} ---\")\n",
    "    try:\n",
    "        df = pd.read_parquet(input_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading parquet: {e}\")\n",
    "        return\n",
    "\n",
    "    # =========================================================\n",
    "    # PART 1: TEXTUAL REPORT & STATISTICAL INSIGHTS (MACRO VIEW)\n",
    "    # =========================================================\n",
    "    # Filter for statistical stability in text report (removing extreme outliers just for the calc)\n",
    "    df_clean = df[(df['pct_slowdown'] > -20) & (df['pct_slowdown'] < 100)].copy()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"MACRO VIEW: INTELLIGENCE REPORT (GENDER PACING DYNAMICS)\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # 1. Descriptive Statistics\n",
    "    stats_df = df_clean.groupby('gender')['pct_slowdown'].agg(\n",
    "        Mean='mean',\n",
    "        Median='median',\n",
    "        Std_Dev='std',\n",
    "        Count='count'\n",
    "    ).round(2)\n",
    "    \n",
    "    # Add Skewness (measure of the \"Long Tail\" of crashing)\n",
    "    stats_df['Skewness'] = df_clean.groupby('gender')['pct_slowdown'].apply(skew).round(2)\n",
    "    \n",
    "    print(\"\\n[1] KEY METRICS TABLE:\")\n",
    "    print(stats_df)\n",
    "    \n",
    "    # 2. Strategy Segmentation\n",
    "    total_m = stats_df.loc['M', 'Count']\n",
    "    total_f = stats_df.loc['F', 'Count']\n",
    "    \n",
    "    wall_m = len(df_clean[(df_clean['gender'] == 'M') & (df_clean['hit_the_wall'] == True)])\n",
    "    wall_f = len(df_clean[(df_clean['gender'] == 'F') & (df_clean['hit_the_wall'] == True)])\n",
    "    \n",
    "    print(f\"\\n[2] THE WALL ANALYSIS (>20% Slowdown):\")\n",
    "    print(f\"   - Men hitting the wall:   {wall_m:,} ({wall_m/total_m:.2%})\")\n",
    "    print(f\"   - Women hitting the wall: {wall_f:,} ({wall_f/total_f:.2%})\")\n",
    "    \n",
    "    # 3. Insight Generation\n",
    "    diff_wall = (wall_m/total_m) - (wall_f/total_f)\n",
    "    print(f\"\\n[3] EXECUTIVE INSIGHT:\")\n",
    "    print(f\"   Men are {diff_wall*100:.1f} percentage points more likely to hit the wall than women.\")\n",
    "    if stats_df.loc['M', 'Skewness'] > stats_df.loc['F', 'Skewness']:\n",
    "        print(\"   The higher skewness in men confirms a behavioral tendency towards extreme positive splits.\")\n",
    "    \n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "   # =========================================================\n",
    "    # PART 2: PUBLICATION-READY PLOTTING \n",
    "    # =========================================================\n",
    "    \n",
    "    # 1. Global Aesthetics (Clean & Professional)\n",
    "    sns.set_theme(style=\"white\", font=\"sans-serif\", font_scale=1.2)\n",
    "    plt.rcParams.update({\n",
    "        'font.family': 'sans-serif',\n",
    "        'font.sans-serif': ['Arial', 'Helvetica', 'DejaVu Sans'],\n",
    "        'axes.spines.top': False,\n",
    "        'axes.spines.right': False,\n",
    "        'axes.linewidth': 1.5,\n",
    "        'xtick.major.width': 1.5,\n",
    "        'ytick.major.width': 1.5\n",
    "    })\n",
    "    \n",
    "    # Standard Figure Size for Journal (approx 2 columns width)\n",
    "    fig_size = (10, 8) \n",
    "    custom_palette = {'M': '#404040', 'F': '#A31F34'} # Grey vs Red\n",
    "\n",
    "    # --- FIGURE 1: DENSITY DISTRIBUTION (KDE) ---\n",
    "    print(\"Generating Figure 1 (Density Distribution - Publishable)...\")\n",
    "    fig1, ax1 = plt.subplots(figsize=fig_size, dpi=300)\n",
    "    \n",
    "    # Plot KDE\n",
    "    sns.kdeplot(\n",
    "        data=df, \n",
    "        x='pct_slowdown', \n",
    "        hue='gender', \n",
    "        fill=True, \n",
    "        common_norm=False, \n",
    "        palette=custom_palette, \n",
    "        alpha=0.4, \n",
    "        linewidth=2.5, \n",
    "        ax=ax1\n",
    "    )\n",
    "    \n",
    "    # Labels & Titles (No Chart Title for Paper - Legends usually go in caption)\n",
    "    ax1.set_xlabel('Pacing Strategy (% Slowdown in 2nd Half)', fontsize=14, fontweight='bold', labelpad=10)\n",
    "    ax1.set_ylabel('Density of Runners', fontsize=14, fontweight='bold', labelpad=10)\n",
    "    \n",
    "    # Reference Lines (Thinner, cleaner)\n",
    "    ax1.axvline(0, color='black', linestyle='--', linewidth=1.5, alpha=0.8)\n",
    "    ax1.text(0.5, ax1.get_ylim()[1]*0.95, 'Even Split', ha='left', fontsize=10, color='black')\n",
    "    \n",
    "    ax1.axvline(20, color='gray', linestyle=':', linewidth=1.5, alpha=0.8)\n",
    "    ax1.text(20.5, ax1.get_ylim()[1]*0.95, 'The Wall (>20%)', ha='left', fontsize=10, color='gray')\n",
    "    \n",
    "    ax1.set_xlim(-15, 60)\n",
    "    \n",
    "    # Clean Legend\n",
    "    sns.move_legend(ax1, \"upper right\", frameon=False, title=None, fontsize=12)\n",
    "    \n",
    "    # Save\n",
    "    out1 = 'Figure_1_Density.tiff'\n",
    "    print(f\"Saving {out1}...\")\n",
    "    fig1.savefig(out1, dpi=300, format='tiff', pil_kwargs={\"compression\": \"tiff_lzw\"}, bbox_inches='tight')\n",
    "    plt.close(fig1)\n",
    "\n",
    "    # --- FIGURE 2: BOXPLOT WITH STATISTICS ---\n",
    "    print(\"Generating Figure 2 (Boxplot with Stats - Publishable)...\")\n",
    "    fig2, ax2 = plt.subplots(figsize=(12, 8), dpi=300) # Slightly wider for categories\n",
    "    \n",
    "    order_cat = [\n",
    "        '1. Elite/Sub-3h (<3:00)',\n",
    "        '2. Advanced (3:00-3:30)',\n",
    "        '3. Intermediate (3:30-4:00)',\n",
    "        '4. Recreational (4:00-4:30)',\n",
    "        '5. Casual (>4:30)'\n",
    "    ]\n",
    "    \n",
    "    # Boxplot\n",
    "    boxplot = sns.boxplot(\n",
    "        data=df, \n",
    "        x='performance_level', \n",
    "        y='pct_slowdown', \n",
    "        hue='gender', \n",
    "        order=order_cat, \n",
    "        palette=custom_palette, \n",
    "        showfliers=False, \n",
    "        linewidth=1.5, \n",
    "        width=0.7,\n",
    "        ax=ax2\n",
    "    )\n",
    "    \n",
    "    # Add transparency manually to boxes\n",
    "    for patch in boxplot.patches:\n",
    "        r, g, b, a = patch.get_facecolor()\n",
    "        patch.set_facecolor((r, g, b, 0.6))\n",
    "    \n",
    "    ax2.set_xlabel('Performance Category', fontsize=14, fontweight='bold', labelpad=10)\n",
    "    ax2.set_ylabel('% Slowdown (2nd Half)', fontsize=14, fontweight='bold', labelpad=10)\n",
    "    \n",
    "    # Clean X-axis labels\n",
    "    clean_labels = [l.split('(')[0].replace('1. ', '').replace('2. ', '').replace('3. ', '').replace('4. ', '').replace('5. ', '').strip() for l in order_cat]\n",
    "    ax2.set_xticklabels(clean_labels, fontsize=11, rotation=0)\n",
    "    \n",
    "    # Reference Lines\n",
    "    ax2.axhline(0, color='black', linestyle='--', linewidth=1, alpha=0.5)\n",
    "    ax2.axhline(20, color='gray', linestyle=':', linewidth=1, alpha=0.5)\n",
    "    \n",
    "    # Statistical Annotation Loop (Recalibrated for new size)\n",
    "    print(\"Calculating Statistical Significance...\")\n",
    "    y_max_plot = 0\n",
    "    \n",
    "    for i, category in enumerate(order_cat):\n",
    "        cat_data = df[df['performance_level'] == category]\n",
    "        men = cat_data[cat_data['gender'] == 'M']['pct_slowdown']\n",
    "        women = cat_data[cat_data['gender'] == 'F']['pct_slowdown']\n",
    "        \n",
    "        if len(men) > 10 and len(women) > 10:\n",
    "            stat, p_val = stats.mannwhitneyu(men, women, alternative='greater')\n",
    "            \n",
    "            # Cohen's d\n",
    "            n1, n2 = len(men), len(women)\n",
    "            s1, s2 = men.std(), women.std()\n",
    "            m1, m2 = men.mean(), women.mean()\n",
    "            pooled_std = np.sqrt(((n1 - 1) * s1**2 + (n2 - 1) * s2**2) / (n1 + n2 - 2))\n",
    "            cohens_d = (m1 - m2) / pooled_std\n",
    "            \n",
    "            # Determine annotation\n",
    "            if p_val < 0.001:\n",
    "                sig_text = \"***\"\n",
    "                font_w = 'bold'\n",
    "            elif p_val < 0.05:\n",
    "                sig_text = \"*\"\n",
    "                font_w = 'bold'\n",
    "            else:\n",
    "                sig_text = \"ns\"\n",
    "                font_w = 'normal'\n",
    "\n",
    "            annot_label = f\"{sig_text}\\n(d={cohens_d:.2f})\"\n",
    "            \n",
    "            # Coordinates\n",
    "            x1, x2 = i - 0.2, i + 0.2\n",
    "            y_box_top = cat_data['pct_slowdown'].quantile(0.85) # Use 85th percentile to avoid outliers\n",
    "            y_line = y_box_top + 3\n",
    "            h_line = 1\n",
    "            \n",
    "            # Draw\n",
    "            col = 'black' if p_val < 0.05 else 'gray'\n",
    "            ax2.plot([x1, x1, x2, x2], [y_line, y_line+h_line, y_line+h_line, y_line], lw=1.2, c=col)\n",
    "            ax2.text((x1+x2)*.5, y_line + h_line + 0.5, annot_label, ha='center', va='bottom', \n",
    "                     color=col, fontsize=9, fontweight=font_w)\n",
    "            \n",
    "            if y_line > y_max_plot: y_max_plot = y_line\n",
    "\n",
    "    ax2.set_ylim(bottom=-20, top=y_max_plot + 25) # Dynamic Y limit\n",
    "    sns.move_legend(ax2, \"upper left\", frameon=False, title=None, fontsize=12)\n",
    "\n",
    "    out2 = 'Figure_2_Boxplot.tiff'\n",
    "    print(f\"Saving {out2}...\")\n",
    "    fig2.savefig(out2, dpi=300, format='tiff', pil_kwargs={\"compression\": \"tiff_lzw\"}, bbox_inches='tight')\n",
    "    plt.close(fig2)\n",
    "\n",
    "    print(\"\\n[SUCCESS] Report printed and Images generated.\")\n",
    "\n",
    "# --- EXECUTION ---\n",
    "generate_comprehensive_analysis(\"Dataset_Berlin_Features_Engineered.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0320a5fe-b101-4eb0-b644-dfacafdfa450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading Data for Statistical Inference from Dataset_Berlin_Features_Engineered.parquet ---\n",
      "\n",
      "================================================================================\n",
      "STATISTICAL INFERENCE REPORT: GENDER DIFFERENCES IN MARATHON PACING\n",
      "================================================================================\n",
      "\n",
      "[1] CHECKING ASSUMPTIONS\n",
      "------------------------------\n",
      "Sample Sizes: Men (N=658,506), Women (N=213,826)\n",
      "   -> STATUS: Large sample size (Central Limit Theorem applies).\n",
      "      Normality is NOT required for T-test validity here.\n",
      "\n",
      "Levene's Test (Equality of Variances):\n",
      "   Statistic=8218.14, p-value=0.00000e+00\n",
      "   -> RESULT: Variances are UNEQUAL (Heteroscedasticity).\n",
      "   -> DECISION: Using Welch's T-test (uncorrected for variance).\n",
      "\n",
      "================================================================================\n",
      "[2] PACING STRATEGY COMPARISON (CONTINUOUS VARIABLE)\n",
      "------------------------------\n",
      "\n",
      "A. Welch's T-Test (Difference of Means):\n",
      "   Mean Slowdown: Men = 10.71% | Women = 8.34%\n",
      "   Difference (Delta): 2.37 percentage points\n",
      "   p-value: 0.00000e+00\n",
      "   -> CONCLUSION: Statistically Significant Difference (p < 0.001).\n",
      "\n",
      "B. Mann-Whitney U Test (Distribution Rank):\n",
      "   p-value: 0.00000e+00\n",
      "   -> CONCLUSION: Men's pacing distribution is stochastically 'slower' (worse) than Women's.\n",
      "\n",
      "C. Cohen's d (Effect Size):\n",
      "   d = 0.2213\n",
      "   -> INTERPRETATION: The biological difference is 'Small'.\n",
      "\n",
      "================================================================================\n",
      "[3] RISK ANALYSIS: PROBABILITY OF 'HITTING THE WALL' (>20% SLOWDOWN)\n",
      "------------------------------\n",
      "Chi-Square Test of Independence:\n",
      "   Chi2 Stat: 7729.62, p-value: 0.00000e+00\n",
      "\n",
      "Risk Metrics:\n",
      "   Probability (Men):   17.61%\n",
      "   Probability (Women): 9.66%\n",
      "   Odds Ratio: 2.00\n",
      "   -> INSIGHT: Men are 2.00x times more likely to hit the wall than women.\n",
      "\n",
      "[VISUALIZATION] Generating Risk Plot ...\n",
      "Saving Risk Plot to Figure_3_Risk_Plot.tiff...\n",
      "Success. Figure 3 generated.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def perform_statistical_inference_report(input_path):\n",
    "    \"\"\"\n",
    "    PERFORMS: DEEP STATISTICAL INFERENCE & HYPOTHESIS TESTING\n",
    "    \n",
    "    Tests Covered:\n",
    "    1. Levene's Test (Assumption Check for Variance)\n",
    "    2. Welch's T-Test (Difference of Means - Robust to unequal variance)\n",
    "    3. Mann-Whitney U (Non-Parametric distribution check)\n",
    "    4. Cohen's d (Effect Size)\n",
    "    5. Chi-Square & Odds Ratio (Dependency of 'Hitting the Wall' on Gender)\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"--- Loading Data for Statistical Inference from {input_path} ---\")\n",
    "    try:\n",
    "        df = pd.read_parquet(input_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading parquet: {e}\")\n",
    "        return\n",
    "\n",
    "    # Filter for analysis stability (-20% to +100% slowdown range)\n",
    "    df_clean = df[(df['pct_slowdown'] > -20) & (df['pct_slowdown'] < 100)].copy()\n",
    "    \n",
    "    men = df_clean[df_clean['gender'] == 'M']['pct_slowdown']\n",
    "    women = df_clean[df_clean['gender'] == 'F']['pct_slowdown']\n",
    "    \n",
    "    n_men = len(men)\n",
    "    n_women = len(women)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"STATISTICAL INFERENCE REPORT: GENDER DIFFERENCES IN MARATHON PACING\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 1. ASSUMPTION CHECKING\n",
    "    # ---------------------------------------------------------\n",
    "    print(\"\\n[1] CHECKING ASSUMPTIONS\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Sample Sizes: Men (N={n_men:,}), Women (N={n_women:,})\")\n",
    "    print(\"   -> STATUS: Large sample size (Central Limit Theorem applies).\")\n",
    "    print(\"      Normality is NOT required for T-test validity here.\")\n",
    "    \n",
    "    # Levene's Test (Homogeneity of Variance)\n",
    "    stat_levene, p_levene = stats.levene(men, women)\n",
    "    print(f\"\\nLevene's Test (Equality of Variances):\")\n",
    "    print(f\"   Statistic={stat_levene:.2f}, p-value={p_levene:.5e}\")\n",
    "    if p_levene < 0.05:\n",
    "        print(\"   -> RESULT: Variances are UNEQUAL (Heteroscedasticity).\")\n",
    "        print(\"   -> DECISION: Using Welch's T-test (uncorrected for variance).\")\n",
    "    else:\n",
    "        print(\"   -> RESULT: Variances are Equal.\")\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 2. HYPOTHESIS TESTING (PACING STRATEGY)\n",
    "    # ---------------------------------------------------------\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"[2] PACING STRATEGY COMPARISON (CONTINUOUS VARIABLE)\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    # A. Welch's T-Test\n",
    "    # H0: Means are equal\n",
    "    t_stat, p_t = stats.ttest_ind(men, women, equal_var=False) \n",
    "    \n",
    "    print(\"\\nA. Welch's T-Test (Difference of Means):\")\n",
    "    print(f\"   Mean Slowdown: Men = {men.mean():.2f}% | Women = {women.mean():.2f}%\")\n",
    "    print(f\"   Difference (Delta): {men.mean() - women.mean():.2f} percentage points\")\n",
    "    print(f\"   p-value: {p_t:.5e}\")\n",
    "    if p_t < 0.001: print(\"   -> CONCLUSION: Statistically Significant Difference (p < 0.001).\")\n",
    "    \n",
    "    # B. Mann-Whitney U Test\n",
    "    # H0: Distributions are equal\n",
    "    u_stat, p_u = stats.mannwhitneyu(men, women, alternative='greater')\n",
    "    \n",
    "    print(\"\\nB. Mann-Whitney U Test (Distribution Rank):\")\n",
    "    print(f\"   p-value: {p_u:.5e}\")\n",
    "    if p_u < 0.001: print(\"   -> CONCLUSION: Men's pacing distribution is stochastically 'slower' (worse) than Women's.\")\n",
    "\n",
    "    # C. Cohen's d (Effect Size)\n",
    "    pooled_std = np.sqrt(((n_men - 1) * men.std()**2 + (n_women - 1) * women.std()**2) / (n_men + n_women - 2))\n",
    "    cohens_d = (men.mean() - women.mean()) / pooled_std\n",
    "    \n",
    "    print(\"\\nC. Cohen's d (Effect Size):\")\n",
    "    print(f\"   d = {cohens_d:.4f}\")\n",
    "    \n",
    "    effect_label = \"Negligible\"\n",
    "    if abs(cohens_d) >= 0.2: effect_label = \"Small\"\n",
    "    if abs(cohens_d) >= 0.5: effect_label = \"Medium\"\n",
    "    if abs(cohens_d) >= 0.8: effect_label = \"Large\"\n",
    "    print(f\"   -> INTERPRETATION: The biological difference is '{effect_label}'.\")\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 3. RISK ANALYSIS (HITTING THE WALL)\n",
    "    # ---------------------------------------------------------\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"[3] RISK ANALYSIS: PROBABILITY OF 'HITTING THE WALL' (>20% SLOWDOWN)\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    contingency = pd.crosstab(df_clean['gender'], df_clean['hit_the_wall'])\n",
    "    \n",
    "    # A. Chi-Square Test\n",
    "    chi2, p_chi2, dof, ex = stats.chi2_contingency(contingency)\n",
    "    \n",
    "    print(f\"Chi-Square Test of Independence:\")\n",
    "    print(f\"   Chi2 Stat: {chi2:.2f}, p-value: {p_chi2:.5e}\")\n",
    "    \n",
    "    # B. Odds Ratio & Probabilities\n",
    "    p_m = contingency.loc['M', True] / (contingency.loc['M', True] + contingency.loc['M', False])\n",
    "    p_f = contingency.loc['F', True] / (contingency.loc['F', True] + contingency.loc['F', False])\n",
    "    \n",
    "    odds_m = p_m / (1 - p_m)\n",
    "    odds_f = p_f / (1 - p_f)\n",
    "    odds_ratio = odds_m / odds_f\n",
    "    \n",
    "    print(f\"\\nRisk Metrics:\")\n",
    "    print(f\"   Probability (Men):   {p_m:.2%}\")\n",
    "    print(f\"   Probability (Women): {p_f:.2%}\")\n",
    "    print(f\"   Odds Ratio: {odds_ratio:.2f}\")\n",
    "    print(f\"   -> INSIGHT: Men are {odds_ratio:.2f}x times more likely to hit the wall than women.\")\n",
    "\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # 4. VISUALIZATION\n",
    "    # ---------------------------------------------------------\n",
    "    print(\"\\n[VISUALIZATION] Generating Risk Plot ...\")\n",
    "    \n",
    "    # --- CONFIGURATION: Reset to Standard Publication Sizes ---\n",
    "    # Instead of poster size, we use standard journal dimensions (approx 8x8 inches)\n",
    "    fig_size = (8, 8)\n",
    "    \n",
    "    # Reset rcParams to ensure fonts are readable on A4 paper (10-14pt range)\n",
    "    plt.rcParams.update({\n",
    "        'font.family': 'sans-serif',\n",
    "        'font.sans-serif': ['Arial', 'Helvetica', 'DejaVu Sans'],\n",
    "        'font.size': 12,              # General text\n",
    "        'axes.labelsize': 14,         # Axis labels (Bold usually)\n",
    "        'axes.titlesize': 14,         # Title (if used)\n",
    "        'xtick.labelsize': 12,        # Tick labels\n",
    "        'ytick.labelsize': 12,\n",
    "        'lines.linewidth': 1.5,       # Thinner lines for paper\n",
    "        'axes.linewidth': 1.5,        # Axis spine width\n",
    "        'axes.spines.top': False,     # Remove top border\n",
    "        'axes.spines.right': False    # Remove right border\n",
    "    })\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=fig_size, dpi=300)\n",
    "    \n",
    "    # Data Preparation\n",
    "    probs = [p_m*100, p_f*100]\n",
    "    genders = ['Men', 'Women']\n",
    "    colors = ['#404040', '#A31F34'] # Dark Grey vs Red\n",
    "    \n",
    "    # --- PLOTTING: Clean Bar Chart ---\n",
    "    # Using alpha=0.9 for solid but not harsh color\n",
    "    bars = ax.bar(genders, probs, color=colors, width=0.6, \n",
    "                  alpha=0.9, edgecolor='black', linewidth=1.5)\n",
    "    \n",
    "    # --- ERROR BARS (95% CI) ---\n",
    "    # Calculate Standard Error\n",
    "    se = [np.sqrt(p*(1-p)/n)*100 for p, n in zip([p_m, p_f], [n_men, n_women])]\n",
    "    \n",
    "    # Capsize reduced to 5 (standard for figures), thinner lines\n",
    "    ax.errorbar(genders, probs, yerr=[1.96*s for s in se], \n",
    "                fmt='none', ecolor='black', capsize=5, elinewidth=1.5, markeredgewidth=1.5)\n",
    "    \n",
    "    # --- LABELS & ANNOTATIONS ---\n",
    "    ax.set_ylabel('Probability of Hitting the Wall (%)', fontsize=14, fontweight='bold', labelpad=10)\n",
    "    \n",
    "    \n",
    "    ax.set_title('') \n",
    "    \n",
    "    # Bar Labels (Percentages)\n",
    "    ax.bar_label(bars, fmt='%.1f%%', padding=4, fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # --- ODDS RATIO ANNOTATION (Professional Box) ---\n",
    "    # Placed centrally above the highest bar\n",
    "    annot_text = f\"Odds Ratio: {odds_ratio:.2f}\\n(Twice the Risk)\\np < 0.001\"\n",
    "    \n",
    "    # Dynamic Y positioning\n",
    "    y_pos_text = max(probs) * 1.25\n",
    "    \n",
    "    ax.text(0.5, y_pos_text, annot_text, \n",
    "            ha='center', va='center', fontsize=12, fontweight='bold', color='black',\n",
    "            bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.5', linewidth=1))\n",
    "    \n",
    "    # Adjust Y-Limit to make room for annotation\n",
    "    ax.set_ylim(0, max(probs) * 1.5)\n",
    "    \n",
    "    # Light horizontal grid for readability\n",
    "    ax.grid(axis='y', linestyle=':', alpha=0.3)\n",
    "    \n",
    "    # --- SAVING (TIFF Format preferred) ---\n",
    "    out_file = 'Figure_3_Risk_Plot.tiff'\n",
    "    print(f\"Saving Risk Plot to {out_file}...\")\n",
    "    \n",
    "    # Using PIL kwargs for compression (LZW is standard for TIFF)\n",
    "    plt.savefig(out_file, dpi=300, format='tiff', pil_kwargs={\"compression\": \"tiff_lzw\"}, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"Success. Figure 3 generated.\")\n",
    "\n",
    "# --- EXECUTION ---\n",
    "# Use the file generated in Step 1 (Feature Engineering)\n",
    "perform_statistical_inference_report(\"Dataset_Berlin_Features_Engineered.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "493ae91e-a3e0-4854-9adb-c9a417987241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading Data for Micro-Analysis from Dataset_Berlin_Features_Engineered.parquet ---\n",
      "\n",
      "================================================================================\n",
      "MICRO VIEW: STRATIFIED ANALYSIS OF THE 'EGO CURSE'\n",
      "Does the gender gap persist when controlling for performance level?\n",
      "================================================================================\n",
      "\n",
      ">>> ANALYZING CATEGORY: 1. Elite/Sub-3h (<3:00)\n",
      "------------------------------------------------------------\n",
      "   Sample: Men (N=40,196), Women (N=2,131)\n",
      "   Avg Slowdown: Men = 3.81%, Women = 2.74%\n",
      "   The 'Ego Gap' (Delta): 1.07 percentage points (Men are slower)\n",
      "   Statistical Significance (p-value): 1.35e-17 -> SIGNIFICANT\n",
      "   Effect Size (Cohen's d): 0.210\n",
      "   Wall Hit Rate (>20% slowdown):\n",
      "      Men: 1.42% | Women: 0.23%\n",
      "      Risk Multiplier: Men are 6.06x more likely to crash.\n",
      "\n",
      ">>> ANALYZING CATEGORY: 2. Advanced (3:00-3:30)\n",
      "------------------------------------------------------------\n",
      "   Sample: Men (N=113,818), Women (N=12,202)\n",
      "   Avg Slowdown: Men = 6.02%, Women = 3.38%\n",
      "   The 'Ego Gap' (Delta): 2.64 percentage points (Men are slower)\n",
      "   Statistical Significance (p-value): 0.00e+00 -> SIGNIFICANT\n",
      "   Effect Size (Cohen's d): 0.380\n",
      "   Wall Hit Rate (>20% slowdown):\n",
      "      Men: 4.61% | Women: 0.81%\n",
      "      Risk Multiplier: Men are 5.68x more likely to crash.\n",
      "\n",
      ">>> ANALYZING CATEGORY: 3. Intermediate (3:30-4:00)\n",
      "------------------------------------------------------------\n",
      "   Sample: Men (N=195,206), Women (N=43,136)\n",
      "   Avg Slowdown: Men = 7.47%, Women = 4.15%\n",
      "   The 'Ego Gap' (Delta): 3.33 percentage points (Men are slower)\n",
      "   Statistical Significance (p-value): 0.00e+00 -> SIGNIFICANT\n",
      "   Effect Size (Cohen's d): 0.412\n",
      "   Wall Hit Rate (>20% slowdown):\n",
      "      Men: 8.07% | Women: 1.50%\n",
      "      Risk Multiplier: Men are 5.37x more likely to crash.\n",
      "\n",
      ">>> ANALYZING CATEGORY: 4. Recreational (4:00-4:30)\n",
      "------------------------------------------------------------\n",
      "   Sample: Men (N=150,105), Women (N=57,777)\n",
      "   Avg Slowdown: Men = 11.71%, Women = 6.73%\n",
      "   The 'Ego Gap' (Delta): 4.98 percentage points (Men are slower)\n",
      "   Statistical Significance (p-value): 0.00e+00 -> SIGNIFICANT\n",
      "   Effect Size (Cohen's d): 0.514\n",
      "   Wall Hit Rate (>20% slowdown):\n",
      "      Men: 18.81% | Women: 4.32%\n",
      "      Risk Multiplier: Men are 4.36x more likely to crash.\n",
      "\n",
      ">>> ANALYZING CATEGORY: 5. Casual (>4:30)\n",
      "------------------------------------------------------------\n",
      "   Sample: Men (N=159,181), Women (N=98,580)\n",
      "   Avg Slowdown: Men = 18.82%, Women = 11.85%\n",
      "   The 'Ego Gap' (Delta): 6.97 percentage points (Men are slower)\n",
      "   Statistical Significance (p-value): 0.00e+00 -> SIGNIFICANT\n",
      "   Effect Size (Cohen's d): 0.574\n",
      "   Wall Hit Rate (>20% slowdown):\n",
      "      Men: 41.58% | Women: 17.66%\n",
      "      Risk Multiplier: Men are 2.35x more likely to crash.\n",
      "\n",
      "================================================================================\n",
      "FINAL VERDICT: DOES THE CURSE EXIST AT ALL LEVELS?\n",
      "================================================================================\n",
      "Category                       | Ego Gap (pp) | Effect Size  | Risk Ratio\n",
      "---------------------------------------------------------------------------\n",
      "1. Elite/Sub-3h (<3:00)        | +1.07        | 0.210        | 6.06x\n",
      "2. Advanced (3:00-3:30)        | +2.64        | 0.380        | 5.68x\n",
      "3. Intermediate (3:30-4:00)    | +3.33        | 0.412        | 5.37x\n",
      "4. Recreational (4:00-4:30)    | +4.98        | 0.514        | 4.36x\n",
      "5. Casual (>4:30)              | +6.97        | 0.574        | 2.35x\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      ">>> CONCLUSION: YES. The 'Ego Curse' is omnipresent.\n",
      "    Men consistently manage pacing worse than women across ALL performance levels,\n",
      "    from Elite Amateurs to Casual Runners. Fitness does NOT cure bad pacing behavior.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import warnings\n",
    "\n",
    "# Suppress repetitive warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def stratified_micro_analysis_report(input_path):\n",
    "    \"\"\"\n",
    "    PERFORMS: MICRO VIEW - STRATIFIED ANALYSIS\n",
    "    \n",
    "    Goals:\n",
    "    1. Loop through each Performance Category (Sub-3h, Advanced, etc.)\n",
    "    2. Perform Independent Statistical Tests (Mann-Whitney U) for each stratum.\n",
    "    3. Calculate the 'Ego Gap' (Difference in Slowdown) for each level.\n",
    "    4. Determine if the behavioral difference persists across all fitness levels.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"--- Loading Data for Micro-Analysis from {input_path} ---\")\n",
    "    try:\n",
    "        df = pd.read_parquet(input_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading parquet: {e}\")\n",
    "        return\n",
    "\n",
    "    # Filter for stability (remove extreme outliers for accurate stats)\n",
    "    df_clean = df[(df['pct_slowdown'] > -20) & (df['pct_slowdown'] < 100)].copy()\n",
    "\n",
    "    # Define Categories in Order of Performance\n",
    "    categories = [\n",
    "        '1. Elite/Sub-3h (<3:00)',\n",
    "        '2. Advanced (3:00-3:30)',\n",
    "        '3. Intermediate (3:30-4:00)',\n",
    "        '4. Recreational (4:00-4:30)',\n",
    "        '5. Casual (>4:30)'\n",
    "    ]\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"MICRO VIEW: STRATIFIED ANALYSIS OF THE 'EGO CURSE'\")\n",
    "    print(\"Does the gender gap persist when controlling for performance level?\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    summary_data = []\n",
    "\n",
    "    for cat in categories:\n",
    "        print(f\"\\n>>> ANALYZING CATEGORY: {cat}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        # Subset Data for this specific category\n",
    "        subset = df_clean[df_clean['performance_level'] == cat]\n",
    "        men = subset[subset['gender'] == 'M']['pct_slowdown']\n",
    "        women = subset[subset['gender'] == 'F']['pct_slowdown']\n",
    "        \n",
    "        n_m, n_f = len(men), len(women)\n",
    "        \n",
    "        # Check if enough data exists\n",
    "        if n_m < 50 or n_f < 50:\n",
    "            print(f\"   [WARNING] Insufficient data for this category (M={n_m}, F={n_f}). Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # 1. Descriptive Stats\n",
    "        mean_m, mean_f = men.mean(), women.mean()\n",
    "        delta = mean_m - mean_f\n",
    "        \n",
    "        # 2. Mann-Whitney U Test (Hypothesis Testing)\n",
    "        # H0: Distribution of Men = Distribution of Women\n",
    "        # H1: Men > Women (One-sided)\n",
    "        u_stat, p_val = stats.mannwhitneyu(men, women, alternative='greater')\n",
    "        \n",
    "        # 3. Cohen's d (Effect Size)\n",
    "        # pooled_std = sqrt( ((n1-1)s1^2 + (n2-1)s2^2) / (n1+n2-2) )\n",
    "        pooled_std = np.sqrt(((n_m - 1) * men.std()**2 + (n_f - 1) * women.std()**2) / (n_m + n_f - 2))\n",
    "        cohens_d = (mean_m - mean_f) / pooled_std\n",
    "        \n",
    "        # 4. Wall Hit Rate (Risk Analysis)\n",
    "        wall_m = len(subset[(subset['gender'] == 'M') & (subset['hit_the_wall'] == True)])\n",
    "        wall_f = len(subset[(subset['gender'] == 'F') & (subset['hit_the_wall'] == True)])\n",
    "        \n",
    "        rate_m = (wall_m / n_m) * 100\n",
    "        rate_f = (wall_f / n_f) * 100\n",
    "        risk_ratio = rate_m / rate_f if rate_f > 0 else 0\n",
    "\n",
    "        # REPORTING THE FINDINGS\n",
    "        print(f\"   Sample: Men (N={n_m:,}), Women (N={n_f:,})\")\n",
    "        print(f\"   Avg Slowdown: Men = {mean_m:.2f}%, Women = {mean_f:.2f}%\")\n",
    "        print(f\"   The 'Ego Gap' (Delta): {delta:.2f} percentage points (Men are slower)\")\n",
    "        \n",
    "        sig_label = \"SIGNIFICANT\" if p_val < 0.001 else \"NOT Significant\"\n",
    "        print(f\"   Statistical Significance (p-value): {p_val:.2e} -> {sig_label}\")\n",
    "        print(f\"   Effect Size (Cohen's d): {cohens_d:.3f}\")\n",
    "        \n",
    "        print(f\"   Wall Hit Rate (>20% slowdown):\")\n",
    "        print(f\"      Men: {rate_m:.2f}% | Women: {rate_f:.2f}%\")\n",
    "        print(f\"      Risk Multiplier: Men are {risk_ratio:.2f}x more likely to crash.\")\n",
    "        \n",
    "        # Store for final summary table\n",
    "        summary_data.append({\n",
    "            'Category': cat,\n",
    "            'Delta (pp)': delta,\n",
    "            'Cohen d': cohens_d,\n",
    "            'Risk Ratio': risk_ratio\n",
    "        })\n",
    "\n",
    "    # FINAL VERDICT TABLE\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"FINAL VERDICT: DOES THE CURSE EXIST AT ALL LEVELS?\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"{'Category':<30} | {'Ego Gap (pp)':<12} | {'Effect Size':<12} | {'Risk Ratio':<10}\")\n",
    "    print(\"-\" * 75)\n",
    "    \n",
    "    consistent_evidence = True\n",
    "    for item in summary_data:\n",
    "        print(f\"{item['Category']:<30} | +{item['Delta (pp)']:<11.2f} | {item['Cohen d']:<12.3f} | {item['Risk Ratio']:.2f}x\")\n",
    "        \n",
    "        # Check consistency (if effect size drops below 0.1, we consider it disappearing)\n",
    "        if item['Cohen d'] < 0.1:\n",
    "            consistent_evidence = False\n",
    "            \n",
    "    print(\"-\" * 75)\n",
    "    \n",
    "    if consistent_evidence:\n",
    "        print(\"\\n>>> CONCLUSION: YES. The 'Ego Curse' is omnipresent.\")\n",
    "        print(\"    Men consistently manage pacing worse than women across ALL performance levels,\")\n",
    "        print(\"    from Elite Amateurs to Casual Runners. Fitness does NOT cure bad pacing behavior.\")\n",
    "    else:\n",
    "        print(\"\\n>>> CONCLUSION: MIXED. The effect varies by level.\")\n",
    "\n",
    "# --- EXECUTION ---\n",
    "stratified_micro_analysis_report(\"Dataset_Berlin_Features_Engineered.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61154afd-aae2-489b-a9c6-7612b3b43a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating Expanded Sample Details from Dataset_Berlin_Cleaned_Analysis_Ready.parquet ---\n",
      "\n",
      "[1] GENDER BREAKDOWN (Fill in the Text):\n",
      "   > Men (N): 659,294 (75.5%)\n",
      "   > Women (N): 214,040 (24.5%)\n",
      "\n",
      "[2] TOP 3 AGE GROUPS:\n",
      "   > 40: 162,234 runners (0.2%)\n",
      "   > 35: 143,728 runners (0.2%)\n",
      "   > 45: 142,610 runners (0.2%)\n",
      "\n",
      "[3] FINISH TIME ROBUSTNESS (Median & IQR):\n",
      "   > M Median: 3:57:46 | IQR: 3:32:02 – 4:28:49\n",
      "   > F Median: 4:26:02 | IQR: 3:58:20 – 4:55:40\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def generate_detailed_demographics(input_path):\n",
    "    print(f\"--- Generating Expanded Sample Details from {input_path} ---\")\n",
    "    df = pd.read_parquet(input_path)\n",
    "    \n",
    "    total_n = len(df)\n",
    "    \n",
    "    # 1. Gender Demographics\n",
    "    counts = df['gender'].value_counts()\n",
    "    pcts = df['gender'].value_counts(normalize=True) * 100\n",
    "    \n",
    "    print(\"\\n[1] GENDER BREAKDOWN (Fill in the Text):\")\n",
    "    print(f\"   > Men (N): {counts.get('M', 0):,} ({pcts.get('M', 0):.1f}%)\")\n",
    "    print(f\"   > Women (N): {counts.get('F', 0):,} ({pcts.get('F', 0):.1f}%)\")\n",
    "    \n",
    "    # 2. Age Distribution\n",
    "    print(\"\\n[2] TOP 3 AGE GROUPS:\")\n",
    "    age_counts = df['age_group'].value_counts().head(3)\n",
    "    for age, count in age_counts.items():\n",
    "        print(f\"   > {age}: {count:,} runners ({count/total_n:.1f}%)\")\n",
    "\n",
    "    # 3. Advanced Time Stats (IQR)\n",
    "    print(\"\\n[3] FINISH TIME ROBUSTNESS (Median & IQR):\")\n",
    "    # Helper for HH:MM:SS\n",
    "    def fmt(seconds):\n",
    "        h = int(seconds // 3600); m = int((seconds % 3600) // 60); s = int(seconds % 60)\n",
    "        return f\"{h}:{m:02d}:{s:02d}\"\n",
    "\n",
    "    stats = df.groupby('gender')['time_seconds'].describe(percentiles=[0.25, 0.75])\n",
    "    \n",
    "    for g in ['M', 'F']:\n",
    "        median = fmt(stats.loc[g, '50%'])\n",
    "        p25 = fmt(stats.loc[g, '25%'])\n",
    "        p75 = fmt(stats.loc[g, '75%'])\n",
    "        print(f\"   > {g} Median: {median} | IQR: {p25} – {p75}\")\n",
    "\n",
    "generate_detailed_demographics(\"Dataset_Berlin_Cleaned_Analysis_Ready.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89831205-aa88-4d53-8abb-0b1bb1456b04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
